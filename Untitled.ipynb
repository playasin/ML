{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"./dataset/images\"\n",
    "\n",
    "image_names = os.listdir(image_dir)\n",
    "images = [os.path.join(image_dir, name) for name in image_names]\n",
    "\n",
    "#for i in images[:100]:\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv2d/kernel:0 is illegal; using conv2d/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d/bias:0 is illegal; using conv2d/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/kernel:0 is illegal; using conv2d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/bias:0 is illegal; using conv2d_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_2/kernel:0 is illegal; using conv2d_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_2/bias:0 is illegal; using conv2d_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense/kernel:0 is illegal; using dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0 is illegal; using dense/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0 is illegal; using dense_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0 is illegal; using dense_2/bias_0 instead.\n"
     ]
    }
   ],
   "source": [
    "image_name_queue = tf.train.string_input_producer(images, shuffle=False)\n",
    "label_name_queue = tf.train.string_input_producer(['./dataset/label/Label.csv'], shuffle=False)\n",
    "\n",
    "image_reader = tf.WholeFileReader() #binary file reader\n",
    "key, raw_image = image_reader.read(image_name_queue) #key는 filename, raw_image는 실제 image data(2진 데이터임)\n",
    "\n",
    "csv_reader = tf.TextLineReader()\n",
    "key, raw_txt = csv_reader.read(label_name_queue)\n",
    "\n",
    "png_image = tf.image.decode_png(raw_image) #컬러 이미지는 r, g, b로 3차원 Matix 형성, 아무 의미 없는 흑백 3차원 이미지임\n",
    "csv_label = tf.decode_csv(raw_txt, record_defaults=[[0]])\n",
    "\n",
    "png_image = tf.reduce_mean(png_image, axis=2) #실습에서는 흑백 이미지 이기 때문에 차원을 2차로 축소\n",
    "png_image = tf.reshape(png_image, [61, 49, 1]) #image size는 높이 * 넓이, 1은 3차원을 만들기 위해 강제로 넣은 값\n",
    "\n",
    "#x, y_ = tf.train.batch([png_image, csv_label], 32) #32는 mini batch size\n",
    "x, y_ = tf.train.shuffle_batch([png_image, csv_label], batch_size=32, capacity=50000, min_after_dequeue=10000)\n",
    "#순차적으로 들어간 값(label)을 가져와서 Training 하면 일부 데이터로 훈련하기 때문에 suffle을 해야 함\n",
    "\n",
    "#print(x.shape)\n",
    "\n",
    "x = tf.cast(x, tf.float32) #x의 값이 integer여서 연산을 위해 float32로 변환\n",
    "\n",
    "#print(y_.shape)\n",
    "y_ = tf.reshape(y_, [-1])\n",
    "#print(y_.shape)\n",
    "\n",
    "y_ = tf.one_hot(y_, depth=3, on_value=1.0, off_value=0.0, axis=-1, dtype=tf.float32) #이해가 안됨\n",
    "#y_ = tf.reduce_mean(y_, axis=2)\n",
    "\n",
    "conv1 = tf.layers.conv2d(x, filters=30, kernel_size=[3, 3], activation=tf.nn.relu, padding=\"SAME\") #일반적으로 kernel_size는 3*3을 선호한다.\n",
    "pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=[2, 2]) #pool_size를 [2, 2]로 써도 무방함\n",
    "\n",
    "#print(pool1.shape)\n",
    "tf.summary.image('feature_map', tf.reduce_mean(pool1, axis=3, keep_dims=True))\n",
    "\n",
    "conv2 = tf.layers.conv2d(pool1, filters=30, kernel_size=[3, 3], activation=tf.nn.relu, padding=\"SAME\") #kernel_size는 3을 써도 무방\n",
    "pool2 = tf.layers.max_pooling2d(conv2, pool_size=2, strides=[2, 2]) \n",
    "\n",
    "conv3 = tf.layers.conv2d(pool2, filters=30, kernel_size=[3, 3], activation=tf.nn.relu, padding=\"SAME\") #일반적으로 kernel_size는 3*3을 선호한다.\n",
    "pool3 = tf.layers.max_pooling2d(conv3, pool_size=2, strides=[2, 2]) #pool_size를 [2, 2]로 써도 무방함\n",
    "\n",
    "fc_input_size = int(pool3.shape[1]) * int(pool3.shape[2]) * int(pool3.shape[3]) #이해가 안됨\n",
    "flat = tf.reshape(pool3, shape=[-1, fc_input_size]) #-1을 넣은 이유는 3차원 큐브가 batch로 인해 32개가 존재하는데\n",
    "                                                    #이것까지 input으로 넣으면 안되기 때문임\n",
    "\n",
    "drop_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "fc1 = tf.layers.dense(flat, units=1000)\n",
    "drop1 = tf.layers.dropout(fc1, drop_prob)\n",
    "\n",
    "fc2 = tf.layers.dense(drop1, units=500)\n",
    "drop2 = tf.layers.dropout(fc2, drop_prob)\n",
    "\n",
    "out = tf.layers.dense(fc2, units=3)\n",
    "\n",
    "for i, var in enumerate(tf.trainable_variables()):\n",
    "    #tf.summary.histogram('variable_{}'.format(i), var)\n",
    "    tf.summary.histogram(var.name, var)\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(y_, out)\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(1e-6).minimize(loss)\n",
    "\n",
    "pred = tf.nn.softmax(out)\n",
    "accuracy = tf.metrics.accuracy(tf.argmax(y_, axis=1), tf.argmax(pred, axis=1))\n",
    "\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "loss: 18.426593780517578\n",
      "accuracy: (0.0, 0.625)\n",
      "step: 100\n",
      "loss: 1.740091323852539\n",
      "accuracy: (0.51937503, 0.51794553)\n",
      "step: 200\n",
      "loss: 2.5059256553649902\n",
      "accuracy: (0.50171876, 0.50155473)\n",
      "step: 300\n",
      "loss: 2.4250662326812744\n",
      "accuracy: (0.50083333, 0.50062293)\n",
      "step: 400\n",
      "loss: 1.9241862297058105\n",
      "accuracy: (0.5028125, 0.50319517)\n",
      "step: 500\n",
      "loss: 2.2419536113739014\n",
      "accuracy: (0.50225002, 0.50205839)\n",
      "step: 600\n",
      "loss: 2.2650203704833984\n",
      "accuracy: (0.50166667, 0.50155991)\n",
      "step: 700\n",
      "loss: 2.4410018920898438\n",
      "accuracy: (0.49964285, 0.4995988)\n",
      "step: 800\n",
      "loss: 1.5648396015167236\n",
      "accuracy: (0.50289065, 0.50280899)\n",
      "step: 900\n",
      "loss: 2.5045018196105957\n",
      "accuracy: (0.5025, 0.50256658)\n",
      "step: 1000\n",
      "loss: 4.186610221862793\n",
      "accuracy: (0.50209373, 0.50206041)\n",
      "step: 1100\n",
      "loss: 2.3643617630004883\n",
      "accuracy: (0.50036931, 0.50034058)\n",
      "step: 1200\n",
      "loss: 2.437666416168213\n",
      "accuracy: (0.49997395, 0.50002605)\n",
      "step: 1300\n",
      "loss: 1.762661337852478\n",
      "accuracy: (0.49906251, 0.49899116)\n",
      "step: 1400\n",
      "loss: 2.974853038787842\n",
      "accuracy: (0.4989509, 0.49904087)\n",
      "step: 1500\n",
      "loss: 1.9989410638809204\n",
      "accuracy: (0.4988125, 0.4988341)\n",
      "step: 1600\n",
      "loss: 1.766627311706543\n",
      "accuracy: (0.49820313, 0.49826279)\n",
      "step: 1700\n",
      "loss: 2.5696001052856445\n",
      "accuracy: (0.49755514, 0.49763006)\n",
      "step: 1800\n",
      "loss: 1.761659860610962\n",
      "accuracy: (0.4985764, 0.49862924)\n",
      "step: 1900\n",
      "loss: 1.9209314584732056\n",
      "accuracy: (0.49883223, 0.49878353)\n",
      "step: 2000\n",
      "loss: 1.911932349205017\n",
      "accuracy: (0.49875, 0.49878186)\n",
      "step: 2100\n",
      "loss: 1.621603012084961\n",
      "accuracy: (0.49870536, 0.4987506)\n",
      "step: 2200\n",
      "loss: 1.6961050033569336\n",
      "accuracy: (0.49840909, 0.4984524)\n",
      "step: 2300\n",
      "loss: 2.4416890144348145\n",
      "accuracy: (0.49864131, 0.49865547)\n",
      "step: 2400\n",
      "loss: 1.7978997230529785\n",
      "accuracy: (0.49843749, 0.49845117)\n",
      "step: 2500\n",
      "loss: 1.7651770114898682\n",
      "accuracy: (0.49873751, 0.49877548)\n",
      "step: 2600\n",
      "loss: 1.9210437536239624\n",
      "accuracy: (0.49841347, 0.49837804)\n",
      "step: 2700\n",
      "loss: 1.572050929069519\n",
      "accuracy: (0.49799767, 0.49796373)\n",
      "step: 2800\n",
      "loss: 1.647223949432373\n",
      "accuracy: (0.49881697, 0.49879506)\n",
      "step: 2900\n",
      "loss: 2.1185576915740967\n",
      "accuracy: (0.49918103, 0.49921364)\n",
      "step: 3000\n",
      "loss: 2.2026145458221436\n",
      "accuracy: (0.49924999, 0.499219)\n",
      "step: 3100\n",
      "loss: 2.0245323181152344\n",
      "accuracy: (0.49930444, 0.49935505)\n",
      "step: 3200\n",
      "loss: 1.24979829788208\n",
      "accuracy: (0.49917969, 0.49916041)\n",
      "step: 3300\n",
      "loss: 1.7236586809158325\n",
      "accuracy: (0.49907196, 0.49907225)\n",
      "step: 3400\n",
      "loss: 1.3128643035888672\n",
      "accuracy: (0.49952206, 0.49954057)\n",
      "step: 3500\n",
      "loss: 2.0668246746063232\n",
      "accuracy: (0.49959821, 0.49954477)\n",
      "step: 3600\n",
      "loss: 2.074875593185425\n",
      "accuracy: (0.49985242, 0.49980909)\n",
      "step: 3700\n",
      "loss: 1.6926498413085938\n",
      "accuracy: (0.5000338, 0.50002533)\n",
      "step: 3800\n",
      "loss: 1.7825462818145752\n",
      "accuracy: (0.50013161, 0.50015622)\n",
      "step: 3900\n",
      "loss: 1.4712018966674805\n",
      "accuracy: (0.50024039, 0.50020826)\n",
      "step: 4000\n",
      "loss: 1.4837976694107056\n",
      "accuracy: (0.50067967, 0.50069511)\n",
      "step: 4100\n",
      "loss: 2.068962812423706\n",
      "accuracy: (0.50122714, 0.5012573)\n",
      "step: 4200\n",
      "loss: 1.05940842628479\n",
      "accuracy: (0.50165176, 0.50165141)\n",
      "step: 4300\n",
      "loss: 1.7298283576965332\n",
      "accuracy: (0.50200582, 0.5019908)\n",
      "step: 4400\n",
      "loss: 1.82854425907135\n",
      "accuracy: (0.50200993, 0.50204498)\n",
      "step: 4500\n",
      "loss: 1.299608588218689\n",
      "accuracy: (0.5020625, 0.5020898)\n",
      "step: 4600\n",
      "loss: 1.1973052024841309\n",
      "accuracy: (0.50224864, 0.50223458)\n",
      "step: 4700\n",
      "loss: 1.1218230724334717\n",
      "accuracy: (0.50214761, 0.50213385)\n",
      "step: 4800\n",
      "loss: 1.8031939268112183\n",
      "accuracy: (0.50256509, 0.50255156)\n",
      "step: 4900\n",
      "loss: 1.4859517812728882\n",
      "accuracy: (0.50258291, 0.50258237)\n",
      "step: 5000\n",
      "loss: 1.725260853767395\n",
      "accuracy: (0.5029, 0.50291818)\n",
      "step: 5100\n",
      "loss: 1.321777582168579\n",
      "accuracy: (0.50310051, 0.50311828)\n",
      "step: 5200\n",
      "loss: 1.4752998352050781\n",
      "accuracy: (0.50334132, 0.50336474)\n",
      "step: 5300\n",
      "loss: 0.9641823768615723\n",
      "accuracy: (0.50341982, 0.50342506)\n",
      "step: 5400\n",
      "loss: 1.009698748588562\n",
      "accuracy: (0.5037905, 0.50380141)\n",
      "step: 5500\n",
      "loss: 1.4576327800750732\n",
      "accuracy: (0.50411361, 0.50410724)\n",
      "step: 5600\n",
      "loss: 1.9071435928344727\n",
      "accuracy: (0.5042634, 0.50425148)\n",
      "step: 5700\n",
      "loss: 1.9670767784118652\n",
      "accuracy: (0.50455046, 0.50458252)\n",
      "step: 5800\n",
      "loss: 1.169554352760315\n",
      "accuracy: (0.50489765, 0.50488061)\n",
      "step: 5900\n",
      "loss: 1.4355343580245972\n",
      "accuracy: (0.50499469, 0.50502032)\n",
      "step: 6000\n",
      "loss: 1.669525384902954\n",
      "accuracy: (0.50560415, 0.50563449)\n",
      "step: 6100\n",
      "loss: 1.3328663110733032\n",
      "accuracy: (0.50565577, 0.50564456)\n",
      "step: 6200\n",
      "loss: 1.7036982774734497\n",
      "accuracy: (0.50571573, 0.50571483)\n",
      "step: 6300\n",
      "loss: 1.4552055597305298\n",
      "accuracy: (0.505997, 0.50598615)\n",
      "step: 6400\n",
      "loss: 1.1546823978424072\n",
      "accuracy: (0.5063867, 0.50638086)\n",
      "step: 6500\n",
      "loss: 1.540776014328003\n",
      "accuracy: (0.50672597, 0.50673455)\n",
      "step: 6600\n",
      "loss: 1.487214207649231\n",
      "accuracy: (0.50670457, 0.50668931)\n",
      "step: 6700\n",
      "loss: 1.5103564262390137\n",
      "accuracy: (0.50714087, 0.50713515)\n",
      "step: 6800\n",
      "loss: 1.893249750137329\n",
      "accuracy: (0.50763327, 0.50764132)\n",
      "step: 6900\n",
      "loss: 1.2008732557296753\n",
      "accuracy: (0.50780344, 0.5078159)\n",
      "step: 7000\n",
      "loss: 1.0369813442230225\n",
      "accuracy: (0.50800449, 0.50798994)\n",
      "step: 7100\n",
      "loss: 1.2831065654754639\n",
      "accuracy: (0.50808096, 0.50805342)\n",
      "step: 7200\n",
      "loss: 1.1827683448791504\n",
      "accuracy: (0.50832033, 0.50832784)\n",
      "step: 7300\n",
      "loss: 1.595153570175171\n",
      "accuracy: (0.50858307, 0.50859046)\n",
      "step: 7400\n",
      "loss: 2.278672218322754\n",
      "accuracy: (0.50874579, 0.50872773)\n",
      "step: 7500\n",
      "loss: 1.4981751441955566\n",
      "accuracy: (0.50897914, 0.50896966)\n",
      "step: 7600\n",
      "loss: 1.3512284755706787\n",
      "accuracy: (0.50901729, 0.5090161)\n",
      "step: 7700\n",
      "loss: 1.4298386573791504\n",
      "accuracy: (0.50926542, 0.50926018)\n",
      "step: 7800\n",
      "loss: 1.4957499504089355\n",
      "accuracy: (0.50969553, 0.50971031)\n",
      "step: 7900\n",
      "loss: 1.0381431579589844\n",
      "accuracy: (0.50989717, 0.50989985)\n",
      "step: 8000\n",
      "loss: 0.6326677799224854\n",
      "accuracy: (0.51028126, 0.51028776)\n",
      "step: 8100\n",
      "loss: 1.197953462600708\n",
      "accuracy: (0.510598, 0.51059282)\n",
      "step: 8200\n",
      "loss: 1.8936383724212646\n",
      "accuracy: (0.51067072, 0.51067322)\n",
      "step: 8300\n",
      "loss: 1.3784236907958984\n",
      "accuracy: (0.51070404, 0.51072162)\n",
      "step: 8400\n",
      "loss: 1.1997416019439697\n",
      "accuracy: (0.51068825, 0.51069814)\n",
      "step: 8500\n",
      "loss: 1.097816824913025\n",
      "accuracy: (0.51081252, 0.5108186)\n",
      "step: 8600\n",
      "loss: 0.8298699855804443\n",
      "accuracy: (0.51084667, 0.51085263)\n",
      "step: 8700\n",
      "loss: 1.4282358884811401\n",
      "accuracy: (0.51090157, 0.51089674)\n",
      "step: 8800\n",
      "loss: 1.417870044708252\n",
      "accuracy: (0.51107246, 0.51104987)\n",
      "step: 8900\n",
      "loss: 1.3616917133331299\n",
      "accuracy: (0.51130968, 0.51132244)\n",
      "step: 9000\n",
      "loss: 1.6023130416870117\n",
      "accuracy: (0.51167363, 0.51168275)\n",
      "step: 9100\n",
      "loss: 1.8040757179260254\n",
      "accuracy: (0.51189905, 0.51188743)\n",
      "step: 9200\n",
      "loss: 1.294004201889038\n",
      "accuracy: (0.51222485, 0.51224393)\n",
      "step: 9300\n",
      "loss: 0.984771192073822\n",
      "accuracy: (0.51240253, 0.51241803)\n",
      "step: 9400\n",
      "loss: 1.0325818061828613\n",
      "accuracy: (0.51252329, 0.51252526)\n",
      "step: 9500\n",
      "loss: 1.3205618858337402\n",
      "accuracy: (0.51268423, 0.5126763)\n",
      "step: 9600\n",
      "loss: 1.266120195388794\n",
      "accuracy: (0.51273435, 0.51274282)\n",
      "step: 9700\n",
      "loss: 1.5734894275665283\n",
      "accuracy: (0.51287693, 0.51288849)\n",
      "step: 9800\n",
      "loss: 0.7703282833099365\n",
      "accuracy: (0.51308352, 0.51308542)\n",
      "step: 9900\n",
      "loss: 1.6070550680160522\n",
      "accuracy: (0.51333648, 0.51333517)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator() #Coordinator는 thread를 관리하는 역할을 함\n",
    "    thread = tf.train.start_queue_runners(sess, coord)\n",
    "    writer = tf.summary.FileWriter('./logs/', sess.graph)\n",
    "    \n",
    "#    _image, _label = sess.run([x, y_])\n",
    "#    for i in range(32):\n",
    "#        plt.figure(i)\n",
    "#        print('age: {}'.format(_label[i]))\n",
    "#        plt.imshow(_image[i])\n",
    "\n",
    "#    print(y_)\n",
    "\n",
    "    for i in range(10000):\n",
    "        _, _loss, _summaries = sess.run([train_op, loss, merged], feed_dict={drop_prob: 0.7})\n",
    "        _pred, _accuracy = sess.run([pred, accuracy], feed_dict={drop_prob: 1.0})\n",
    "        writer.add_summary(_summaries, i)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print('step: {}'.format(i))\n",
    "            print('loss: {}'.format(_loss))\n",
    "            print('accuracy: {}'.format(_accuracy))\n",
    "            #print('prediction 1: {}'.format(tf.argmax(_pred[0])))\n",
    "            #print('prediction 2: {}'.format(tf.argmax(_pred[1])))\n",
    "            #print('prediction 3: {}'.format(tf.argmax(_pred[2])))\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
