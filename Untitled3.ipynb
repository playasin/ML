{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_dataset():\n",
    "    up = [i for i in range(10)]\n",
    "    down = [9-i for i in range(10)]\n",
    "\n",
    "    with open('./est_dataset.csv', 'w') as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for i in range(1000):\n",
    "            writer.writerow([1] + up)\n",
    "            writer.writerow([0] + down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    dataset = tf.contrib.data.TextLineDataset('./est_dataset.csv')\n",
    "    dataset = dataset.shuffle(7777).batch(10)\n",
    "\n",
    "    itr = dataset.make_one_shot_iterator()\n",
    "\n",
    "    batch = itr.get_next()\n",
    "\n",
    "    batch = tf.decode_csv(batch, record_defaults=[[0]]*11)\n",
    "\n",
    "    train = tf.cast(tf.stack(batch[1:], axis=1), dtype=tf.float32)\n",
    "    label = tf.cast(batch[0], dtype=tf.float32)\n",
    "\n",
    "    return train, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    layer1 = tf.layers.dense(features, 10)\n",
    "    layer2 = tf.layers.dense(layer1, 10)\n",
    "    out = tf.layers.dense(layer2, 1)\n",
    "    \n",
    "    out = tf.reshape(out, [-1])\n",
    "    \n",
    "    global_step = tf.train.get_global_step()\n",
    "    loss = tf.losses.sigmoid_cross_entropy(labels, out)\n",
    "    train_op = tf.train.GradientDescentOptimizer(1e-2).minimize(loss, global_step)\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, train_op=train_op, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './est/logs', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./est/logs\\model.ckpt-300\n",
      "INFO:tensorflow:Saving checkpoints for 301 into ./est/logs\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.000384771, step = 301\n",
      "INFO:tensorflow:global_step/sec: 724.101\n",
      "INFO:tensorflow:loss = 0.000294791, step = 401 (0.138 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into ./est/logs\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000229553.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x296cf5737f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = tf.estimator.Estimator(model_fn, model_dir='./est/logs')\n",
    "est.train(input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.  8.  7.  6.  5.  4.  3.  2.  1.  0.] 0.0\n",
      "[ 9.  8.  7.  6.  5.  4.  3.  2.  1.  0.] 0.0\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.] 1.0\n",
      "[ 9.  8.  7.  6.  5.  4.  3.  2.  1.  0.] 0.0\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.] 1.0\n",
      "[ 9.  8.  7.  6.  5.  4.  3.  2.  1.  0.] 0.0\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.] 1.0\n",
      "[ 9.  8.  7.  6.  5.  4.  3.  2.  1.  0.] 0.0\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.] 1.0\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.] 1.0\n"
     ]
    }
   ],
   "source": [
    "train, label = input_fn()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    _train, _label = sess.run([train, label])\n",
    "    for t, l in zip(_train, _label):\n",
    "        print(t, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
